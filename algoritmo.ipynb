{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construción de algoritmo de prueba\n",
    "Este código está diseñado para procesar textos y extraer cierta información de una serie de documentos. Una vez que se ha extraído la información deseada, se guarda en un archivo CSV (Comma Separated Values) para su posterior uso o análisis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrollador: Rosinver Alejandro Vasquez Duran\n",
    "\n",
    "google colab: https://colab.research.google.com/drive/1xdxcWEzhhAY9tEXqlk9Hzun7uFVXQ_iw?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download es_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar librearias \n",
    "import csv\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import re\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo de lenguaje de spaCy\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   document_name                                           document\n",
      "0             86    Señor/señora: Daniel Roberto Torres Gómez  L...\n",
      "1            470    Atención: Ana Miguel Jiménez Rodríguez  Le e...\n",
      "2             16    Oiga!!!! Juan Pablo Fernández Muñoz  Esperam...\n",
      "3            165    Querido/a Carlos Miguel Pérez Pérez,  Espera...\n",
      "4            114    Estimadisimo/a Daniel Cristina Rodríguez Gon...\n"
     ]
    }
   ],
   "source": [
    "# como leer un archivo csv delimitado por | y con codificacion utf-8\n",
    "df = pd.read_csv('documentos.csv', sep='|', encoding='utf-8')\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicación:\n",
    "- El script comienza inicializando una lista vacía llamada \"output_data\" que se utilizará para almacenar los datos de salida.\n",
    "\n",
    "- Luego, utiliza dos expresiones regulares para buscar patrones de montos y fechas en los documentos. Estas expresiones regulares se guardan en las variables \"monto_pattern\" y \"fecha_pattern\".\n",
    "\n",
    "- A continuación, el script itera sobre cada fila del dataframe \"df\" y procesa el documento en cada iteración. Utiliza la librería spacy para realizar un análisis de entidades en el documento y busca entidades de tipo \"PER\" (persona) y \"LOC\" (ubicación). Cuando encuentra una entidad de tipo \"PER\", agrega el nombre de la persona a la lista de salida y cuando encuentra una entidad de tipo \"LOC\", agrega la ubicación a la lista de salida.\n",
    "\n",
    "- Luego, utiliza las expresiones regulares para buscar patrones de fechas en el documento y, si encuentra una fecha, la agrega a la lista de salida.\n",
    "\n",
    "- Finalmente, utiliza la expresión regular para buscar un patrón de monto en el documento y, si encuentra un monto, lo agrega a la lista de salida.\n",
    "\n",
    "- Una vez que se han procesado todos los documentos, el script crea un dataframe a partir de la lista de salida y lo guarda en un archivo CSV llamado \"output.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.csv >done<\n"
     ]
    }
   ],
   "source": [
    "# Inicializa una lista vacía para almacenar los datos de salida\n",
    "output_data = []\n",
    "\n",
    "# Extrae el costo con una expresión regular\n",
    "monto_pattern = r\"\\b\\d{1,3}(,\\d{3})*\\.\\d{2}\\b\"\n",
    "# patron de fecha yyyy- mm-dd o dd-mm-yyyy\n",
    "fecha_pattern = r\"\\d{1,4}[/-]\\d{1,2}[/-]\\d{4}\"\n",
    "fecha_pattern2 =r'\\d{4}-\\d{2}-\\d{2}'\n",
    "\n",
    "# Itera sobre cada fila del dataframe\n",
    "for index, row in df.iterrows():\n",
    "    doc = nlp(row['document'])\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PER':\n",
    "            # Agrega el nombre de la persona a la lista de salida\n",
    "            # agregar 4 tokens del nombre de la persona para filtrar los nombre compuestos por 4 palabras\n",
    "            output_data.append({'nombre_cliente': ' '.join(ent.text.split()[:4])})\n",
    "            break\n",
    "    #buscar localizacion\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'LOC':\n",
    "            # Agrega la localización a la lista de salida\n",
    "            output_data[-1]['ciudad'] = ent.text\n",
    "            break\n",
    "    #buscar fecha pattern\n",
    "    matches = re.findall(fecha_pattern , row['document'])\n",
    "    for match in matches:\n",
    "        date = parser.parse(match)\n",
    "        # Agrega la fecha a la lista de salida\n",
    "        output_data[-1]['fecha'] = date.strftime('%Y-%m-%d')\n",
    "    #buscar fecha pattern2 \n",
    "    matches2 = re.findall(fecha_pattern2 , row['document'])\n",
    "    for match2 in matches2:\n",
    "        date2 = parser.parse(match2)\n",
    "        # Agrega la fecha a la lista de salida\n",
    "        output_data[-1]['fecha'] = date2.strftime('%Y-%m-%d')\n",
    "        \n",
    "    monto = re.search(monto_pattern, row['document']).group()\n",
    "    # cambiar los numeros del formato 000,000,000.00 a 000000000.00\n",
    "    monto = monto.replace(',', '')\n",
    "    # Agrega el costo a la lista de salida\n",
    "    output_data[-1]['monto'] = monto\n",
    "    \n",
    "# Crea un dataframe a partir de la lista de salida\n",
    "output_df = pd.DataFrame(output_data)\n",
    "\n",
    "# Guarda el dataframe en un archivo csv\n",
    "output_df.to_csv('output.csv', sep='|', index=False)\n",
    "\n",
    "print('output.csv >done<')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salida de resultado.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado.csv >done<\n"
     ]
    }
   ],
   "source": [
    "#concatenar los archivos csv de documentos y resultado\n",
    "dfout = pd.concat([df, output_df], axis=1)\n",
    "#guardar el archivo csv\n",
    "dfout.to_csv('resultado.csv', sep='|', index=False)\n",
    "\n",
    "print('resultado.csv >done<')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7c5817727678c332fb9fa5aff0185fec398eda4559a601173fdef72aa27c3a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
